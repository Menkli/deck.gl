<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.4.5">Jekyll</generator><link href="http://deck.gl/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="http://deck.gl/blog/" rel="alternate" type="text/html" /><updated>2017-07-24T11:32:56-07:00</updated><id>http://deck.gl/blog/</id><title type="html">Deck.gl Blog</title><subtitle>A blog for deck.gl: WebGL-powered data visualization</subtitle><author><name>Uber</name></author><entry><title type="html">The Birth of a Visualization Framework Suite</title><link href="http://deck.gl/blog/2017/visualization-framework-suite" rel="alternate" type="text/html" title="The Birth of a Visualization Framework Suite" /><published>2017-07-23T00:00:00-07:00</published><updated>2017-07-23T00:00:00-07:00</updated><id>http://deck.gl/blog/2017/visualization-framework-suite</id><content type="html" xml:base="http://deck.gl/blog/2017/visualization-framework-suite">&lt;h1 id=&quot;the-birth-of-a-visualization-framework-suite&quot;&gt;The Birth of a Visualization Framework Suite&lt;/h1&gt;

&lt;h2 id=&quot;a-simple-idea&quot;&gt;A Simple Idea&lt;/h2&gt;

&lt;p&gt;The basic idea behind today’s by taking Uber’s most popular open source Visualization frameworks, and aligning their websites, documentation and examples, and providing links between the websites, we can make our various frameworks significantly easier to discover and use for both new and experienced users.&lt;/p&gt;

&lt;h2 id=&quot;the-frameworks&quot;&gt;The Frameworks&lt;/h2&gt;

&lt;p&gt;The visualization frameworks that are part of our initial suite are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://uber.github.io/deck.gl/&quot;&gt;deck.gl&lt;/a&gt; - High performance WebGL powered layers for geospatial and infovis use cases.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://uber.github.io/react-map-gl/&quot;&gt;react-map-gl&lt;/a&gt; - React components for Mapbox GL (integrates seamlessly with deck.gl)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://uber.github.io/react-vis&quot;&gt;react-vis&lt;/a&gt; - An extensive set of React charting components.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://uber.github.io/luma.gl&quot;&gt;luma.gl&lt;/a&gt; - WebGL2 components powering deck.gl&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-develop-a-framework-suite&quot;&gt;Why Develop a Framework Suite?&lt;/h2&gt;

&lt;p&gt;While each framework in the suite has a different focus, they are quite complementary to each other (in fact, at Uber we have developed a number applications that use all of these frameworks) so there is a clear value in making it easy to discover and learn these frameworks.&lt;/p&gt;

&lt;h2 id=&quot;the-making-of-the-suite&quot;&gt;The Making of the Suite?&lt;/h2&gt;

&lt;h2 id=&quot;a-push-on-documentation-and-examples&quot;&gt;A push on Documentation and Examples&lt;/h2&gt;

&lt;p&gt;To create the suite, we had to bring all frameworks up to the same level of completion and polish, and we have spent significant efforts into improving the websites, documentation and examples of these frameworks.&lt;/p&gt;

&lt;p&gt;Great software should have great documentation. We made a big push on documentation in the release of deck.gl about 3 months ago and the response has been overwhelmingly good. So we decided to apply the same standards to all the frameworks in the suite.&lt;/p&gt;

&lt;p&gt;The launch of the frameworks suite means that all the frameworks have consistent websites, with documentation, example gallery etc are now all organized in the same way and maintained at similar standards of polish and completeness.&lt;/p&gt;

&lt;h2 id=&quot;interlinking-the-documentation-sites&quot;&gt;Interlinking the Documentation Sites&lt;/h2&gt;

&lt;p&gt;Users often use several of the frameworks. Using deck.gl, luma.gl and react-map-gl is perhaps the most common combination. Previously, users had to deal with documentation of very different structure and quality spread out over multiple sites.&lt;/p&gt;

&lt;p&gt;Each framework in the suite now has a drop down in its header bar to allow easy navigation to the other frameworks.&lt;/p&gt;

&lt;p&gt;In addition, each framework has been assigned a color scheme, giving the user a visual cue to where he or she is in the suite (i.e. which framework’s docs are currently being shown). This should be helpful now that the different frameworks follow the same documentation style.&lt;/p&gt;

&lt;h2 id=&quot;new-releases&quot;&gt;New Releases&lt;/h2&gt;

&lt;p&gt;In concert with the unification of the framework documentation websites, we are also releasing new versions of some of the frameworks in the suite.&lt;/p&gt;

&lt;h3 id=&quot;react-map-gl-v3&quot;&gt;react-map-gl v3&lt;/h3&gt;

&lt;p&gt;A major under-the-hood upgrade, this release also makes more Mapbox GL features available to React users, significantly strengthens the React encapsulation of Mapbox GL, simplifies installation, and adds support for some advanced use cases.&lt;/p&gt;

&lt;p&gt;Release highlights:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The documentation and website are completely rewritten (and made part of the suite, of course)&lt;/li&gt;
  &lt;li&gt;Multi-touch (pinch to zoom and rotate etc) is now supported (e.g. for mobile devices)&lt;/li&gt;
  &lt;li&gt;New React components are available (Markers, Popups etc), matching the native API.&lt;/li&gt;
  &lt;li&gt;A new architecture supports some advanced use cases, like automatically hiding the map when tilting beyond the mapbox 60 degree limit, something we use in “hybrid” applications that layer 3D visualizations on top of mapbox (using deck.gl, of course).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;lumagl-v4&quot;&gt;luma.gl v4&lt;/h3&gt;

&lt;p&gt;v4 brings complete support for WebGL2 (which represents a major upgrade of the WebGL API). But there are a number of other significant improvements that round off this major release.&lt;/p&gt;

&lt;p&gt;Release highlights:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Full WebGL2 Support&lt;/li&gt;
  &lt;li&gt;WebGL Capability Management&lt;/li&gt;
  &lt;li&gt;WebGL State Management&lt;/li&gt;
  &lt;li&gt;GLSL Module System&lt;/li&gt;
  &lt;li&gt;Debug and Profiling Support&lt;/li&gt;
  &lt;li&gt;Library Size Optimizations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That said, many users will probably appreciate the dramatically improved luma.gl documentation more than any single feature.&lt;/p&gt;

&lt;h3 id=&quot;deckgl-v41&quot;&gt;deck.gl v4.1&lt;/h3&gt;

&lt;p&gt;deck.gl v4.1 is now based on luma.gl v4. The blog post &lt;a href=&quot;http://uber.github.io/deck.gl/blog/2017/introducing-deckgl-v4&quot;&gt;introducing deck.gl v4&lt;/a&gt; mentioned our plans to introduce more GPU based computing into future versions deck.gl (e.g. GPU based data processing and aggregation), and the inclusion of luma.gl v4 is a major enabler for that effort.&lt;/p&gt;

&lt;p&gt;The new release also  adds a couple of previously “teased” WebGL2 example layers, the &lt;a href=&quot;http://uber.github.io/deck.gl/blog/2017/wind-map&quot;&gt;Wind Map&lt;/a&gt; layers. These layers are now offered as part of a reusable, stand-alone example.&lt;/p&gt;

&lt;h3 id=&quot;react-vis-17&quot;&gt;react-vis 1.7&lt;/h3&gt;

&lt;p&gt;The priority of react-vis version 1.7 is documentation. Every documentation page has been written from scratch, entirely rewritten or reviewed since version 1.6. Since version 1.5, we’ve been publishing react-vis as a bundle, making it easy to use on sandbox environments such as codepen or codesandbox for quick experimentation. We also unified the documentation style introduced by deck.gl v3.&lt;/p&gt;

&lt;h2 id=&quot;whats-next-for-the-suite&quot;&gt;What’s Next for the Suite?&lt;/h2&gt;

&lt;p&gt;We expect to gradually bring out new frameworks, and when it makes sense, add them to the suite. That said, we’d like to keep a high bar for membership in this suite. The frameworks in the suite should be of general interest to the visualization community.&lt;/p&gt;

&lt;p&gt;As an example, we have also open sourced other supporting, more special-purpose frameworks (e.g. viewport-mercator-project, or the seer Chrome debug extension), but these are not as frequently accessed directly by users and we do not plan make them part of the interlinked documentation suite.&lt;/p&gt;

&lt;h2 id=&quot;feedback-welcome&quot;&gt;Feedback Welcome&lt;/h2&gt;

&lt;p&gt;One of the biggest goals of the new suite is to make these frameworks easier to use, and simpler to discover, for &lt;strong&gt;you&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;We’d love to hear from you if you have ideas about the suite and how we could improve it to help you. Just ping us in the issues section of any of the framework repositories on github, and let us know what you think.&lt;/p&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;

&lt;p&gt;Ib Green, on behalf of
The Visualization Team at Uber&lt;/p&gt;</content><author><name>{&quot;display_name&quot;=&gt;&quot;Ib Green&quot;, &quot;github_username&quot;=&gt;&quot;ibgreen&quot;}</name></author><category term="Visualization" /><category term="Framework Suite" /><summary type="html">The Birth of a Visualization Framework Suite</summary></entry><entry><title type="html">Introducing luma.gl v4.0</title><link href="http://deck.gl/blog/2017/introducing-lumagl-v4" rel="alternate" type="text/html" title="Introducing luma.gl v4.0" /><published>2017-07-23T00:00:00-07:00</published><updated>2017-07-23T00:00:00-07:00</updated><id>http://deck.gl/blog/2017/introducing-lumagl-v4</id><content type="html" xml:base="http://deck.gl/blog/2017/introducing-lumagl-v4">&lt;h1 id=&quot;introducing-lumagl-v40&quot;&gt;Introducing luma.gl v4.0&lt;/h1&gt;

&lt;h2 id=&quot;version-40&quot;&gt;Version 4.0&lt;/h2&gt;

&lt;p&gt;In many ways v4.0 is the biggest luma.gl release to date. It is a major upgrade that brings full WebGL2 support to luma.gl, as well as adding advanced features such as GL state management and a shader module system.&lt;/p&gt;

&lt;h2 id=&quot;major-updates&quot;&gt;Major Updates&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;New Documentation&lt;/li&gt;
  &lt;li&gt;Full WebGL2 Support with WebGL Capability Management&lt;/li&gt;
  &lt;li&gt;WebGL State Management&lt;/li&gt;
  &lt;li&gt;GLSL Module System&lt;/li&gt;
  &lt;li&gt;Seer Debug Integration&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;new-documentation&quot;&gt;New Documentation&lt;/h3&gt;

&lt;p&gt;Before even going into the wealth of new features in luma.gl v4, the documentation has been completely rewritten&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New documentation site, aligned with other frameworks in the same visualization suite, such as deck.gl, react-map-gl and react-vis.&lt;/li&gt;
  &lt;li&gt;Extensive overhaul of documentation structure and contents
If you are an existing user of luma.gl this might be the biggest immediate benefit for you.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;complete-webgl2-support&quot;&gt;Complete WebGL2 support&lt;/h3&gt;

&lt;p&gt;A short overview of WebGL2 and some of the additions to the luma.gl API that have been made to support it.&lt;/p&gt;

&lt;h2 id=&quot;new-classes&quot;&gt;New Classes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Texture2DArray&lt;/code&gt;, - e.g. for texture atlases&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Texture3D&lt;/code&gt; - for volumetric rendering or 3D lookup tables&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Query&lt;/code&gt; - Asynchronously query for occlusions, transform feedback, timings&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Sampler&lt;/code&gt; - Let’s shaders sample same texture in different ways&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;FenceSync&lt;/code&gt; - Get notified when GPU reaches certain point in command stream&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TransformFeedback&lt;/code&gt; - Get output from vertex shaders&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;VertexArrayObject&lt;/code&gt; - Stores multiple attribute bindings&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that &lt;code class=&quot;highlighter-rouge&quot;&gt;VertexArrayObject&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Query&lt;/code&gt; can be used in WebGL1 with certain restrictions.&lt;/p&gt;

&lt;p&gt;WebGL2 introduces objects that collect state allowing applications to switch state with a single call:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;VertexArrayObject&lt;/code&gt;s - holds a set of vertex array buffer bindings&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Sampler&lt;/code&gt; - holds a set of texture sampling parameters&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TransformFeedback&lt;/code&gt; - holds a set of transform feedback output buffer bindings.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;UniformBufferLayout&lt;/code&gt; - a helper class to simplify manipulation of uniform values in “std140” memory layout.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;webgl2-support&quot;&gt;WebGL2 Support&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;luma.gl classes for the new WebGL2 objects (&lt;code class=&quot;highlighter-rouge&quot;&gt;FenceSync&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Query&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Sampler&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Texture2DArray&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Texture3D&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;TransformFeedback&lt;/code&gt;).&lt;/li&gt;
  &lt;li&gt;New &lt;code class=&quot;highlighter-rouge&quot;&gt;UniformBufferLayout&lt;/code&gt; helper class to make uniform buffer usage easy.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Textures&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Renderbuffers&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Framebuffers&lt;/code&gt; updated to handle all the new WebGL2 image formats, including floating point textures, and multiple render targets.&lt;/li&gt;
  &lt;li&gt;Every existing WebGL class has been overhauled and has received additional methods that expose WebGL2 functionality whenever available.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;new-features&quot;&gt;New Features&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;WebGL state management and shader module&lt;/code&gt;: after the launch of luma.gl v3, the feedback we received from some long-time WebGL programmers suggested that luma.gl had the right API surface with two big exceptions: it lacked a system for managing global WebGL state, and a solution for managing shader modules. Both of these deficiencies have been addressed in luma.gl v4.&lt;/p&gt;

&lt;h3 id=&quot;webgl-capability-management&quot;&gt;WebGL Capability Management&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Dramatically simplifies building apps that run on both WebGL1 and WebGL2, seamlessly leveraging extensions when available.&lt;/li&gt;
  &lt;li&gt;Helps apps to query if a WebGL feature is available on the current platform - regardless of whether it is available through WebGL2 or a WebGL1 extension.&lt;/li&gt;
  &lt;li&gt;When a feature can be provided either through WebGL2 or a WebGL1 extension, luma.gl provides a single API that transparently uses the available implementation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;webgl-state-management&quot;&gt;WebGL State Management&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Enables apps to work with WebGL context state without having to worry about global side effects, addressing one of the major weak spots of the WebGL API.&lt;/li&gt;
  &lt;li&gt;Lets apps temporarily change global context state without having to do expensive queries to remember what values to restore it to.&lt;/li&gt;
  &lt;li&gt;Tracks changes to the context happening outside of luma.gl to ensure that global state always remains synchronized.&lt;/li&gt;
  &lt;li&gt;Prevents unnecessary calls to set state to current value.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;glsl-module-system&quot;&gt;GLSL Module System&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;ShaderAssembler&lt;/code&gt; system allows shader code to be split into composable pieces.&lt;/li&gt;
  &lt;li&gt;It is completely optional, the application can use raw shader strings, &lt;code class=&quot;highlighter-rouge&quot;&gt;glslify&lt;/code&gt;, the &lt;code class=&quot;highlighter-rouge&quot;&gt;ShaderAssembler&lt;/code&gt; system or any other tools in isolation or combination to generate its shaders.&lt;/li&gt;
  &lt;li&gt;Optionally integrates with a &lt;code class=&quot;highlighter-rouge&quot;&gt;ShaderCache&lt;/code&gt; to ensure textually equivalent shaders are only compiled once.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;seer-integration-debug-and-profiling&quot;&gt;Seer Integration (Debug and Profiling)&lt;/h3&gt;

&lt;p&gt;Debugging GLSL shaders can be one of the more frustrating part of WebGL programming, and from the start, luma.gl has included strong debugging support (including optionally logging values attributes and uniforms before draw calls, throwing exceptions showing the exact location of parsing errors in GLSL source code etc). In v4 we have taken this to the next level by integrating with the Seer chrome plugin. It is now possible to list and inspect all your &lt;code class=&quot;highlighter-rouge&quot;&gt;Model&lt;/code&gt; instances directly in the Chrome dev tools, check attributes and uniforms, and even see performance timings from the last draw calls directly in the debugger.&lt;/p&gt;

&lt;h2 id=&quot;webgl2-api-highlights&quot;&gt;WebGL2 API highlights&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;WebGL2 constants added to &lt;code class=&quot;highlighter-rouge&quot;&gt;GL&lt;/code&gt; export&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Textures
    &lt;ul&gt;
      &lt;li&gt;Can now create from &lt;code class=&quot;highlighter-rouge&quot;&gt;WebGLBuffers&lt;/code&gt; in addition to typed arrays&lt;/li&gt;
      &lt;li&gt;Tons of new texture formats&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Compressed textures from&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;GLSL &lt;code class=&quot;highlighter-rouge&quot;&gt;dFdx&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;dFdy&lt;/code&gt; Texture derivatives - (e.g. to compute normals in fragment shader)&lt;/li&gt;
      &lt;li&gt;GLSL &lt;code class=&quot;highlighter-rouge&quot;&gt;texelFetch&lt;/code&gt; - (e.g. for manual bilinear filtering)&lt;/li&gt;
      &lt;li&gt;GLSL &lt;code class=&quot;highlighter-rouge&quot;&gt;textureGrad&lt;/code&gt; - (e.g. for tweaking mipmap levels)&lt;/li&gt;
      &lt;li&gt;Immutable texture?&lt;/li&gt;
      &lt;li&gt;Integer texture - uint sampler&lt;/li&gt;
      &lt;li&gt;Texture LOD&lt;/li&gt;
      &lt;li&gt;GLSL &lt;code class=&quot;highlighter-rouge&quot;&gt;textureOffset&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;pixelStore&lt;/li&gt;
      &lt;li&gt;sRGB&lt;/li&gt;
      &lt;li&gt;texture vertex (e.g. for displacement mapping)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Vertex Formats (GL.HALF_FLOAT)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;GLSL
    &lt;ul&gt;
      &lt;li&gt;centroid&lt;/li&gt;
      &lt;li&gt;discard&lt;/li&gt;
      &lt;li&gt;flat_smooth_interpolators&lt;/li&gt;
      &lt;li&gt;non_square_matrix&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TBD
    &lt;ul&gt;
      &lt;li&gt;Uniform buffers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Misc
    &lt;ul&gt;
      &lt;li&gt;New blending modes: &lt;code class=&quot;highlighter-rouge&quot;&gt;GL.MIN&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;GL.MAX&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Efficiency&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;gpgpu-programming-highlights&quot;&gt;GPGPU Programming Highlights&lt;/h2&gt;

&lt;p&gt;Enabling GPGPU (General Purpose GPU) programming, i.e. the use of the GPU for computations in addition to rendering is a major goal for luma.gl.&lt;/p&gt;

&lt;p&gt;While much more is planned for future releases, this is a quick overview of some of the features in v4 that facilitate GPGPU use cases:&lt;/p&gt;

&lt;h3 id=&quot;buffers&quot;&gt;Buffers&lt;/h3&gt;

&lt;p&gt;Memory Management* - A big part of efficient GPGPU computing is setting up memory so that the GPU can access it, and manipulating and reading back that memory in an efficient way. It is therefore important to be aware of what tools WebGL and luma.gl provide to manipulate memory.&lt;/p&gt;

&lt;p&gt;Buffers represent memory on the GPU. One can think of it as “uploading”
a memory to the GPU. The cost of the upload depends on the GPU architecture
but it should not be considered free.&lt;/p&gt;

&lt;p&gt;The buffers are just memory block, the interpretation depends on how they
are used.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Method&lt;/th&gt;
      &lt;th&gt;Version&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Buffer.subData&lt;/td&gt;
      &lt;td&gt;WebGL1*&lt;/td&gt;
      &lt;td&gt;Enables updating only part of a buffer on the GPU. Note that WebGL2 provides additional control parameters&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Buffer.copySubData&lt;/td&gt;
      &lt;td&gt;WebGL2&lt;/td&gt;
      &lt;td&gt;Enables direct copy between buffers on GPU without moving memory to the CPU&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Buffer.getSubData&lt;/td&gt;
      &lt;td&gt;WebGL2&lt;/td&gt;
      &lt;td&gt;Enables readback of memory from&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;textures&quot;&gt;Textures&lt;/h3&gt;

&lt;p&gt;Textures also contain memory and is organized depending on the texture width, height, format etc.&lt;/p&gt;

&lt;p&gt;Textures can be used as a source of data to the GPU so they can be quite useful in GPGPU computing, either when the WebGL API does not directly support buffers (often the case in WebGL1) or to achieve special results (e.g. implementing accumulation through blending).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Floating Point Textures&lt;/strong&gt; - Usually, the most useful textures for GPGPU computing are floating point textures (i.e. each color value can be a 16 bit or 32 bit float, rather than just a small integer). In WebGL1, the support for floating point textures depends on the availability of extensions, and there are many limitations and variations between platforms. In WebGL2, the situation is much better, floating point textures are available by default, although some uses are still dependent on extensions (the luma.gl capability management system makes this easy to check).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;transform-feedback&quot;&gt;Transform Feedback&lt;/h3&gt;

&lt;p&gt;While WebGL2 does not support pure compute shaders, it does allow the application to capture the output of the vertex shader stage (in WebGL1 the processed vertices are sent directly to the fragment shader and are not accessible to the application).&lt;/p&gt;

&lt;p&gt;To use transform feedback, instantiate the &lt;code class=&quot;highlighter-rouge&quot;&gt;TransformFeedback&lt;/code&gt; class and add the buffers you want the GPU to store processed vertex data in. Also, let your program know what varyings you want to extract into &lt;code class=&quot;highlighter-rouge&quot;&gt;Buffers&lt;/code&gt; before you link it:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;const transformFeedback = new TransformFeedback(gl, {})
.bindBuffersForVaryings({
  gl_Position: new Buffer(gl, {}),
  vColor: new Buffer(gl, {}),
  vNormal: new Buffer(gl, {}),
});

transformFeedback.begin(GL.POINTS);
const program = new Program(gl, {vs, fs, transformFeedback}})
const program = new Program(gl, {vs, fs, transformFeedback}})
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;For more details on how transform feedback works refer to the &lt;a href=&quot;https://www.khronos.org/opengl/wiki/Transform_Feedback&quot;&gt;OpenGL Wiki&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;disabling-the-fragment-shader&quot;&gt;Disabling the Fragment Shader&lt;/h3&gt;

&lt;p&gt;When using transform feedback, you are often not interested in the output of the fragment shader. If so, you can stop it from running to improve performance. Just turn off rasterization in your draw calls.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;program.draw({
  settings: {
    [GL.RASTERIZER_DISCARD]: true
  }
});
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s Next&lt;/h2&gt;

&lt;p&gt;Development luma.gl is by no means finished and here are some highlights of what can be expected in coming releases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Library Size&lt;/strong&gt; - WebGL2 is a big API and together with the new advanced features in luma.gl, it means that the luma.gl library has grown considerably in size. Expect a bigger effort already for the next minor release to reduce the size of the library and the impact it has on the size of application bundles.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;GPGPU computing&lt;/strong&gt; - This remains an area of active development for luma.gl and deck.gl. We expect to add new examples to demonstrate GPGPU techniques, and the luma.gl API will continue to evolve to make sure the necessary code in applications becomes as clean and easy to work with as possible.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;More Shader Modules&lt;/strong&gt; - More shader modules will be provided. While the shader module system introduced in v4 is already useful, the real power will come from having a library of composable, documented, and tested shader modules. More examples will also be rewritten to take advantage of the shader module system.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;WebGL2 (Continued)&lt;/strong&gt; - More WEBGL2 enabled examples will be added, giving developers an easy way to start using the new classes and methods, and we plan to track and integrate any new extensions for WebGL2 as they become available in browsers.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Seer Integration&lt;/strong&gt; - The Seer Chrome extension is a highly flexible and extensible system, and further leveraging Seer should surface much more information about the state of various luma.gl objects in future releases, further simplifying debugging and profiling of luma.gl applications.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;display_name&quot;=&gt;&quot;Ib Green&quot;, &quot;github_username&quot;=&gt;&quot;ibgreen&quot;}</name></author><category term="Visualization" /><category term="WebGL" /><category term="Luma.gl" /><summary type="html">Introducing luma.gl v4.0</summary></entry><entry><title type="html">Wind Map</title><link href="http://deck.gl/blog/2017/wind-map" rel="alternate" type="text/html" title="Wind Map" /><published>2017-04-17T00:00:00-07:00</published><updated>2017-04-17T00:00:00-07:00</updated><id>http://deck.gl/blog/2017/wind-map</id><content type="html" xml:base="http://deck.gl/blog/2017/wind-map">&lt;div class=&quot;youtube-wrapper&quot;&gt;
  &lt;iframe src=&quot;https://www.youtube.com/embed/4qm_dO4nAk0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

A few weeks ago I set on trying out new WebGL 2.0 features with deck.gl. WebGL 2.0 brings plenty of new goodies to be used for game development, creative coding and data visualization like instancing, floating-point textures, transform feedback, multiple render targets, and more. With this in mind, and inspired by the work of Cameron Beccario, Viegas and Wattenberg, and NASA, I created a WebGL 2.0 wind map demo using deck.gl.

This [interactive demo](http://philogb.github.io/page/wind/) enables you to change the map’s perspective by using cmd + drag; toggle between vector field and particle layers on the left panel, and use the slider to change the time of day to see wind change for a 72 hour period. 

## Some interesting insights

The screenshot below shows wind speed near Mount Washington, which has the fastest winds in the US.

![Wind speed near Mount Washington](../img/wind2.jpg)

Something interesting to look at as well are the wind corridors being formed in Florida at specific times.

![Extreme wind corridors in Florida](../img/wind9.gif)

## Under the hood

There are thousands of stations that capture wind speed, orientation and temperature with different time granularity. If you turn all layers off you’ll see yellow dots that represent each one of the stations we’re getting data from.

![Wind stations across the US](../img/wind4.jpg)

### The Delaunay Interpolation Layer

For this example though one of the challenges was to be able to get a uniform distribution of wind speed, direction and temperature that could be sampled at any point of the map, not simply at each station. In order to do this we created a Delaunay tessellation for the stations, and then rendered the mesh to a floating-point texture, to get GPU-interpolated values into an image. In this case we map wind direction to the red channel, wind speed to green, temperature to blue and elevation to alpha.

![Delaunay mesh](../img/wind-delaunay-1.jpg)

You can see the interpolated wind data rendered to an image below:

![Delaunay interpolation layer](../img/wind-delaunay-2.jpg)

### The Vector Field Layer

The next step was to use instancing to create a regular vector field layer. For this we created tetrahedron instances to serve as arrows and used the texture above to set their orientation, color and size. If you use the slider on the left you’ll also see that there’s GPU interpolation. Although we sample data every hour, we interpolate between the textures so we can estimate the values at each minute. Since we already had the Delaunay model we also used that to give an approximation of the elevation in the US:

![Vector field layer](../img/wind7.jpg)

### The Particle Layer

Finally we used [transform feedback](https://open.gl/feedback), which enables us to only use the vertex shader for data processing and updating every particle’s position in real-time. We throw a random sample of particles (~1MM) that get updated by the texture data, and then render those on the screen. Every particle has a TTL (time-to-live); when the TTL expires it gets repositioned at a random location on the map. Blending reveals where the biggest concentration of particles are.

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Particles&quot; src=&quot;../img/wind3.gif&quot;&gt;
&lt;/p&gt;

And that’s it! Three custom layers built with deck.gl to bring this wind map to life. Check out [the example](http://philogb.github.io/page/wind/) and feel free to provide feedback!</content><author><name>{&quot;display_name&quot;=&gt;&quot;Nicolas Belmonte&quot;, &quot;github_username&quot;=&gt;&quot;philogb&quot;}</name></author><category term="Case Study" /><category term="Visualization" /><category term="WebGL" /><summary type="html"></summary></entry><entry><title type="html">Rendering A Minecraft World With deck.gl</title><link href="http://deck.gl/blog/2017/rendering-minecraft-with-deckgl" rel="alternate" type="text/html" title="Rendering A Minecraft World With deck.gl" /><published>2017-04-12T00:00:00-07:00</published><updated>2017-04-12T00:00:00-07:00</updated><id>http://deck.gl/blog/2017/rendering-minecraft-with-deckgl</id><content type="html" xml:base="http://deck.gl/blog/2017/rendering-minecraft-with-deckgl">While working on [deck.gl v4](./introducing-deckgl-v4.html), I decided to have some fun and built a [Minecraft Chunk Viewer](http://pessimistress.github.io/minecraft/) in the browser. Drag in a region file from your own world and explore the world in depth! Totally not cheating.

- [Region files](http://minecraft.gamepedia.com/Chunk_format) are in your Minecraft's save folder with names like **r.12.34.mca**. Check [this page](http://minecraft.gamepedia.com/.minecraft) to see where to find them.
- Drag to rotate; drag while holding *shift* to pan
- Use the slider to slice the world
- Hover over a block to see details
- Click on the minimap to select other chunks; click while holding *shift* to select multiple chunks

&lt;p aligh=&quot;center&quot;&gt;
  &lt;img width=&quot;900&quot; src=&quot;../img/minecraft1.gif&quot;&gt;
&lt;/p&gt;

For those who are interested, I'll dive into how this was built.

## An Overview of the App

The chunk viewer itself is a pretty straight forward React one page app. Here are some of the critical components of the [source code](https://github.com/Pessimistress/minecraft-chunk-viewer/tree/master/src):

+ `app.js` - Root. Lays out all the components and stores all the states.
+ `components/orbit-controller.js`
    &lt;br /&gt;The component that handles user interaction with the 3D view. It maps pointer and wheel input to changes in the deck.gl viewport. It is rendered as the parent of the `DeckGL` canvas to capture all pointer events.
+ `minecraft-layer/`
    &lt;br /&gt;A custom deck.gl layer that does the rendering magic.
+ `utils/mca-parser.js`
    &lt;br /&gt;Util functions that parse a **.mca** file. Based on the work of [minecraft-region](https://github.com/maxogden/minecraft-region).
+ `utils/orbit-viewport.js`
    &lt;br /&gt;An implementation of the deck.gl [Viewport](http://uber.github.io/deck.gl/#/documentation/api-reference/viewport) class, used by the `OrbitController`.

When the file is loaded and chunks are selected, the app calls `readChunks()` from the parser utils to update the data. The world is represented as an array of block objects, each containing information such as position (in-game `x` `y` `z` coordinates), block id (type of block), block data (block-specific metadata), biome and light level.

Because deck.gl does not do dynamic z-sorting (to prioritize performance), it's important to draw the solid blocks before the transparent ones to avoid depth clipping.
Luckily, in this use case the interesting view angle is always from top down. When loading the blocks, they are sorted by `y` from bottom to top, so that the lower levels are rendered first.

The data is then passed in to create an instance of the `MinecraftLayer` - the custom layer that renders Minecraft blocks.

## The Minecraft Layer

### The MinecraftLayer Class

[MinecraftLayer](https://github.com/Pessimistress/minecraft-chunk-viewer/tree/master/src/minecraft-layer/index.js) extends deck.gl's base `Layer` class. At initialization (`initializeState()`), it does the following:

- Creates a single instanced model that defines what to render. An instanced model duplicates the same geometry (&quot;instance&quot;) many times with slight variations. Naturally in Minecraft, each instance is a cube.
- Adds attributes. The attributes are per instance and determines how each cube will look. Each attribute has an `update` function that will only be called once when `props.data` changes. The attributes carry the following information to the vertex shader:
  + `position` - the `x` `y` `z` coordinates of the block
  + `blockId` and `blockData` - [block data values](http://minecraft.gamepedia.com/Data_values)
  + `temperature` and `humidity` - used to calculate biome shading
  + `lighting` - the light level of a block, either from sky light or self illumination
- Loads textures. The layer loads three textures that are sent to the shaders as uniforms:
  + `blocks.png` - this is the encoded block metadata, will discuss below.
  + `textures.png` - this is an all-up texture atlas of all Minecraft textures.
  + `foliage.png` - this is the definition of biome colors, as explained [here](http://www.planetminecraft.com/blog/biomes-controlling-color/).

At each rendering cycle, the method `draw()` is called to render the model to the WebGL context.

### Passing Block Metadata to the GPU

An unique challenge in this project is that there are many variables playing into the appearance of a block. Each face of the cube has its own texture and biome shading behavior. To make a single cube geometry work with as many block types as possible, I introduced &quot;transforms&quot; that can be applied to each the block: rotation (e.g. logs), size (e.g. half slabs), translation (e.g. ladders) and face offset (e.g. flowers).

![Block Definition Examples](../img/minecraft2.png)

All together the texture properties and block transforms add up to 20+ float attributes per instance. Sadly WebGL1 does not handle arrays easily. To avoid creating a long list of attributes, I opt to encode all the block definitions into one image texture. There is an 8-pixels slot assigned to each (`blockId`, `blockData`) combination, and each channel (`r` `g` `b` `a`) can be used to store one property. Now the vertex shader can look up block definitions on the fly:

![Encoded Block Definition](https://github.com/Pessimistress/minecraft-chunk-viewer/blob/master/static/data/blocks.png?raw=true)

### The Shaders

At render time, the vertex shader looks up block definitions using id, data value and face index. The block-level transforms are applied to vertex positions and normals. Texture coordinates are passed to the fragment shader, where colors are touched up with biome shading, lighting, mouse hover highlight, etc.

The Y-slicer position is passed in as a uniform and essentially reduces the alpha of all blocks above the given level. It is an inexpensive operation but extremely useful when you need to peek into the belly of a chunk. I am quite pleased with how it works out.

&lt;p&gt;&lt;a href=&quot;../img/minecraft3.png&quot; title=&quot;This is a very dry diagram. Click with discretion&quot; target=&quot;_blank&quot;&gt;&lt;img width=&quot;900&quot; src=&quot;../img/minecraft3.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

Here's a big gotcha regarding the block definition lookup. When I first implemented it, the rendering result was a mess: grass blocks were consistently rendered as wood planks, dirt as cobble stones, and block orientations were all weird. I double and then triple checked my asset generation script, but everything looked correct. It seemed that the vertex shader was just reading the wrong rgb values out of the texture.

Turns out that *the rgb precision is affected by the alpha channel*. When alpha is 255, the rgb values are read exactly as what I wrote into the image. As the alpha decreases, the rgb values start to show an increasing margin of error. It makes sense in image display because when opacity is very low, the single-digit difference is rounded away by blending; but this becomes a big problem when I use them to encode texture indices. This behavior is also apparently GPU-dependent, because the same image worked on my Macbook and did not on iOS. The advice is to avoid using the alpha channel if possible, or at least keep the number in the upper range.

### Optimization

A typical chunk is over 20k blocks, that is 240k triangles to render. When multiple chunks are selected, it quickly becomes too much for the browser. A cheap improvement is to turn on face culling (`gl.enable(gl.CULL_FACE)`), which immediately reduce the number of fragments in half.

To make things even faster, we can skip the surfaces that are right against a solid block. Only those that are behind air, transparent texture (e.g. water, leaves) or irregular shaped blocks (e.g. stairs) need to be rendered.

When parsing the region file, a hashmap is built to track whether each block is opaque or not. An accessor `getIsBlockOpaque` is introduced to the Minecraft Layer to look up the transparency flag for any block coordinates. The layer then creates an attribute `instanceVisibilities` which tells the vertex shader what's next to each face of the cube. Here's a comparison between rendering without and with this optimization:

![Face Visibility](../img/minecraft4.jpg)


## Cool, What's Next?

This all started as a weekend project. deck.gl was great as a foundation for this kind of experiment -- it took care of most of the chores such as attribute mangement, update cycles, projection and picking. I was able to spend most of my time focusing on Minecraft-specific code.

Right now the chunk viewer only supports limited Minecraft block types, because I got lazy halfway into scraping the Wiki. My hacky tricks with cubes obviously will not work with every entity out there (no mobs, for example). But surely there are a lot more improvements I can make. Checkout the [issues list](https://github.com/Pessimistress/minecraft-chunk-viewer/issues) and make a suggestion!

Now pardon me as I go dig up that diamond ore.</content><author><name>{&quot;display_name&quot;=&gt;&quot;Xiaoji Chen&quot;, &quot;github_username&quot;=&gt;&quot;Pessimistress&quot;}</name></author><category term="Case Study" /><category term="Custom Layer" /><category term="Non-Geospatial" /><summary type="html">While working on deck.gl v4, I decided to have some fun and built a Minecraft Chunk Viewer in the browser. Drag in a region file from your own world and explore the world in depth! Totally not cheating.</summary></entry><entry><title type="html">Introducing deck.gl v4.0</title><link href="http://deck.gl/blog/2017/introducing-deckgl-v4" rel="alternate" type="text/html" title="Introducing deck.gl v4.0" /><published>2017-04-03T00:00:00-07:00</published><updated>2017-04-03T00:00:00-07:00</updated><id>http://deck.gl/blog/2017/introducing-deckgl-v4</id><content type="html" xml:base="http://deck.gl/blog/2017/introducing-deckgl-v4">## Introducing deck.gl v4.0

We've just released a new major version of deck.gl, so this is a good time to share some information about the improvements that went into the new version the rationale behind them, and provide some hints on our thoughts about the future of deck.gl.

### What Motivated the Release?

When we did our first [external announcement](https://eng.uber.com/deck-gl-framework/) of deck.gl in November 2016 (announcing the deck.gl v3 release), we also stated our intention to improve and expand deck.gl's layer catalog in future releases. This is a major part of what we are doing now through the deck.gl v4 release.

deck.gl v3 saw rapid adoption across a number of internal data visualization applications here at Uber, and it didn't take long before an impressive list of new layers had been developed to support these applications. For layers that were reused between multiple applications, it became clear that open sourcing them in a new official deck.gl release would likely benefit both internal and external developers.

In deck.gl v4, the core layer catalog in deck.gl effectively doubles in size to over a dozen [layers](https://uber.github.io/deck.gl/#/documentation/layer-catalog). These layers are carefully audited, tested and documented, and cover a significantly wider array of geospatial visualization use cases.

Obviously, while the new layers are the big stars of the release, deck.gl v4 includes more than just the layers. It stems from almost five months of intensive development, and incorporates improvements addressing a long list of comments, suggestions, bug reports and feature requests, from both internal and external users. If you are already a deck.gl v3 user, you will find few areas in v4, whether in terms of APIs, documentation, examples or actual code, that haven't received some level of additional polish.

### Why a Major Version Bump?

We take backwards compatibility of deck.gl very seriously. deck.gl follows [semver](http://semver.org) versioning rules, which require that any change to existing functionality, no matter how small, is accompanied by a bump of the major version number, from 3 to 4 in this case.

Obviously, the addition of a set of new layers would not by itself change any existing functionality, and thus only require a minor version bump (e.g. deck.gl v3.1). However, as part of the release preparations, we conducted an extensive API audit of both the new v4 layers and the existing v3 layers and found that doing a small set of changes to existing v3 layer APIs would allow us to make the APIs of all layers considerably more consistent and the whole framework more cohesive and logical, which was clearly the right long-term choice.

In spite of the major version bump, deck.gl v4 remains highly compatible with deck.gl v3, both in terms of public APIs and the way layers work. Also, to ensure a smooth transition, we provide an [upgrade guide](https://uber.github.io/deck.gl/#/documentation/overview/upgrade-from-v3) and we expect the upgrade effort for applications to be minimal.

## A Growing Layer Catalog

From the very beginning, deck.gl has always been a geospatial data visualization framework, and geospatial use cases will always be our top priority. The new layers added to the [layer catalog](https://uber.github.io/deck.gl/#/documentation/layer-catalog) are widely used in geospatial data analysis within Uber and we hope they will help solve the problems that deck.gl users face every day.

### [`GeoJsonLayer`](https://uber.github.io/deck.gl/#/documentation/layer-catalog/geojson-layer)

&lt;p aligh=&quot;center&quot;&gt;
	&lt;img width=&quot;900&quot; src=&quot;../img/screenshot-geojson.png&quot;&gt;
&lt;/p&gt;

The `GeoJsonLayer` is designed to render geometry primitives in the widely-accepted GeoJSON data format. `GeoJsonLayer` itself is very powerful as it renders multiple types of geometry primitives, including points, lines, multilines, polygons and multipolygons all at once. Moreover, it can render polygons and multipolygons in different styles, currently supporting filled and outline styles in non-extruded (2D) mode, and filled and wireframe styles in extruded (3D) mode.

The flexibility of `GeoJsonLayer` combined with deck.gl's high rendering performance makes it possible to render large amounts of data on the city or even the worldwide scale, as shown in the [`GeoJsonLayer` example on our demo site](https://uber.github.io/deck.gl/#/examples/core-layers/geojson-layer).

### [`PathLayer`](https://uber.github.io/deck.gl/#/documentation/layer-catalog/path-layer)

&lt;p aligh=&quot;center&quot;&gt;
	&lt;img width=&quot;900&quot; src=&quot;../img/screenshot-path.png&quot;&gt;
&lt;/p&gt;

The `PathLayer` is created to render a path comprising multiple line segments, specified by a sequence of coordinates. The path drawn has customizable width and mitered or rounded line joints.

### [`PolygonLayer`](https://uber.github.io/deck.gl/#/documentation/layer-catalog/polygon-layer)

&lt;p aligh=&quot;center&quot;&gt;
	&lt;img width=&quot;900&quot; src=&quot;../img/screenshot-polygon.png&quot;&gt;
&lt;/p&gt;

The `PolygonLayer` renders general flat or extruded polygons specified by a &quot;closed&quot; sequence of coordinates, following the GeoJSON specification for polygon features. Polygons can be rendered as filled or outlined in non-extruded (2D) mode and filled or wireframed in extruded (3D) mode. This layer supports rendering convex, concave and &quot;donut&quot; polygons (with holes).

### [`IconLayer`](https://uber.github.io/deck.gl/#/documentation/layer-catalog/icon-layer)

&lt;p aligh=&quot;center&quot;&gt;
	&lt;img width=&quot;900&quot; src=&quot;../img/screenshot-icon.png&quot;&gt;
&lt;/p&gt;

The `IconLayer` allows the user to render customizable markers on top of the base map. Multiple icons can be used in a single layer through a texture atlas and a configuration object in JSON. The size of the icons can be separately controlled and bounded with user-specified values.

### [`PointCloudLayer`](https://uber.github.io/deck.gl/#/documentation/layer-catalog/point-cloud-layer)

&lt;p aligh=&quot;center&quot;&gt;
	&lt;img width=&quot;900&quot; src=&quot;../img/screenshot-point-cloud.png&quot;&gt;
&lt;/p&gt;

The `PointCloudLayer` is designed to visualize 3D point cloud data, usually generated from sensors like LIDAR and stereoscopic cameras. Point cloud data can contain position, normal and color values to control the style of rendered points, which are &quot;billboarded&quot; towards the user.

### [`GridLayer`](https://uber.github.io/deck.gl/#/documentation/layer-catalog/grid-layer) and [`HexagonLayer`](https://uber.github.io/deck.gl/#/documentation/layer-catalog/hexagon-layer)

&lt;p aligh=&quot;center&quot;&gt;
	&lt;img width=&quot;900&quot; src=&quot;../img/screenshot-hexagon.png&quot;&gt;
&lt;/p&gt;

deck.gl v4 introduces two new &quot;auto-aggregating&quot; layers that complement the `ScreenGridLayer` from v3. The `GridLayer` and `HexagonLayer` draw equal-area rectangular or hexagonal cells. These layers go beyond directly displaying the supplied data on the map, in that they don't draw one cell per data point, like most deck.gl layers do. They first aggregate (or &quot;bin&quot;) the user-provided data points into cells, and then draw the cells using the aggregated values to control properties like color and height, effectively rendering grid-based **heatmaps**.

Aggregation is an exciting new direction for deck.gl as we want to not only provide layers that are visually compelling to our users, but that are also smart.

Finally, note that the new `GridLayer` and `HexagonLayer` are different from the existing `ScreenGridLayer` as both the rendered geometry and the aggregation boundaries are in world coordinates rather than screen coordinates. Another difference is that the new layers also support both flat (2D) and extruded (3D) cells.

## Layer extrusion and lighting

As mentioned in the previous sections, some deck.gl layers now support extrusion. Extrusion can be enabled by setting the `extruded` property to true, if available. Users can provide a `getElevation` accessor to control how much each individual element should extrude.

To make extrusion appear natural and visually pleasing, deck.gl v4 now has an experimental lighting module that provides basic shading of 3D layers. It has very straightforward APIs and users should be able to understand them simply by looking at the examples that come with deck.gl. It's worth mentioning that since they're experimental, the public APIs might change in the future release of deck.gl.

## Interactive Documentation

deck.gl's documentation has been significantly improved and reorganized in response to user feedback. In particular, every layer now has an interactive layer browser allowing users to tweak all properties of the layer and see how they affect the final rendering of layers while reading the docs. It also serves as an intuitive tool for users to select appropriate layers for their use cases.

&lt;p aligh=&quot;center&quot;&gt;
	&lt;img width=&quot;900&quot; src=&quot;../img/interactive-layer-browser.png&quot;&gt;
&lt;/p&gt;

## Stand-Alone Examples

deck.gl v3 came with what was essentially a single example interleaved with the complicated build scripts and extensive package dependencies of the main library. This has been called out by many entry-level users, so the deck.gl team decided to provide multiple stand-alone examples with minimal configuration files. These examples should jump start the learning process of deck.gl and developers can easily copy them out and bootstrap their own apps from them. These examples are located in the [example folder](https://github.com/uber/deck.gl/tree/master/examples) in deck.gl's main repository.

## Interoperability Examples

To leverage your data visualization knowledge with the tools you are familiar with, we also provide [examples to demonstrate the interoperability](https://github.com/uber/deck.gl/tree/master/examples/svg-interoperability) between deck.gl and regular SVG-based visualizations. For example, one can use the modularized d3-* utilities for layout calculation, and have deck.gl take care of the rendering, thereby avoiding heavy DOM manipulation and enabling GPU-accelerated rendering of up to millions of elements.

## What’s Next?

deck.gl v4 is an important milestone for us, but what's next? While we haven't finalized any plans for a possible deck.gl v4.1 or v5 release yet, we have many ideas about improvements and directions we would like deck.gl to evolve along. Some examples are:

### More and Better Layers

Layers are how deck.gl creates value for most users, so adding more layers is on the top of our list. We will always keep improving support for the geospatial visalizations while also considering support for abstract/non-geospatial visualizations in the [InfoVis](https://en.wikipedia.org/wiki/Information_visualization) area.

We also encourage all deck.gl users and developers to consider sharing your fancy new layers with the deck.gl community (github pull requests are welcome). If your layers help address some common needs and/or accomplish tasks common across multiple areas of data visualization, they might even end up being included in the core layers catalog of deck.gl in the next release!

### Text Rendering Support

Text provides crucial information in many data visualization applications and can be implemented in various ways depending on specific use cases. Using WebGL to render text labels or geometries is both performant and versatile, but can be non-trivial to implement. In deck.gl v4 we are not providing any official support for text rendering besides a basic sample layer called [&quot;LabelLayer&quot;](https://github.com/uber/deck.gl/tree/master/examples/sample-layers/label-layer). This is an area we are actively exploring.

### Expanding and Improving Aggregation

The new aggregating layers in deck.gl v4 are only scratching the surface of what can be done in terms of adding data processing intelligence to deck.gl. More advanced aggregation algorithms are being researched, and will be implemented if they are useful for our internal or external customers.

### More Data Processing (possibly on GPU) for Geospatial Data Analysis

As we march forward in the geospatial data analysis field, it's obvious that the single-threaded Javascript engine in our browsers will soon be overwhelmed by computation-intensive tasks. We can solve this by seeking help from the backend, but not without its own limitations. The recently-released [WebGL 2.0](https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext) standard provides a way for front-end developers to access powerful GPUs on every desktops and laptops that was not possible in the past. With features like transform feedback, we might be able to vastly accelerate many computational tasks in geospatial data analysis.

We have already started experimenting with those powerful features in WebGL 2.0 to do not only rendering, but also data aggregation on the GPU.

### Improved Layer Composition

In the new v4 release of deck.gl, some new layers like `GeoJsonLayer` and `HexagonLayer` are what we call **composite** layers, as they are actually built by composing other core deck.gl layers. Composite layers have their own props but also leverage underlying layers for their capabilities. This kind of composition greatly reduces the effort required for creating new layers and makes the internal structure of many layers much cleaner. In future releases, we will continue making composite layer development easier by decoupling different sets of layer functionality and continuously improving our guides and docs.

### More Advanced Picking Support

Picking (i.e. mouse selection) is one of the most common tasks of interactive data visualization applications and is a core functionality we provide with deck.gl. We have ideas for improving picking by adopting better picking boundary arbitration (bigger pick targets), supporting square or polygon area picking, etc.

### Performance

Performance is always at the front of our minds as deck.gl, from the first day, was designed to be a **high performance** visualization framework. Many under-the-hood performance improvements went into the v4 release, including a 3.5~4X faster scatterplot layer, faster 64-bit maths, and ~2X performance boost in picking, etc. In the future, we are considering implementing a better WebGL state manager that faciliates resource sharing and reuse, a better layer manager that manages and updates resources in a smarter way, and a better rendering engine that only allows necessary data to hit GPUs from the very beginning.

## Final Words

Finally, just to dispel any doubt from our users, we would like to reiterate our commitment that deck.gl will remain a &quot;geospatial visualization first&quot; framework. The non-geospatial use cases we are working on will not compromise our focus on maintaining and improving the geospatial visualization aspects of deck.gl. To the contrary, as we mentioned earlier in this article, users can expect see even more &quot;advanced&quot; geospatial processing functionalities to the future releases of deck.gl.

## Contributors

deck.gl v4 was created by the Visualization Team at Uber. It is the result of a collaboration between a number of amazing contributors, including:
[**Nicolas Garcia Belmonte**](https://github.com/philogb),
[**Xiaoji Chen**](https://github.com/Pessimistress),
[**Balthazar Gronon**](https://github.com/apercu),
[**Shan He**](https://github.com/heshan0131),
[**Shaojing Li**](https://github.com/shaojingli),
[**Eric Socolofsky**](https://github.com/ericsoco),
[**Yang Wang**](https://github.com/gnavvy)
and [**many others**](https://github.com/uber/deck.gl/graphs/contributors).</content><author><name>{&quot;display_name&quot;=&gt;&quot;Ib Green&quot;, &quot;github_username&quot;=&gt;&quot;ibgreen&quot;}</name></author><category term="Visualization" /><category term="WebGL" /><summary type="html">Introducing deck.gl v4.0</summary></entry></feed>